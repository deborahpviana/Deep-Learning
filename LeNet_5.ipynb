{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LeNet-5.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/deborahpviana/Deep-Learning/blob/master/LeNet_5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WaEI5tuPVeDl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install tensorflow-gpu"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eMu8ofhzW7m3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import optimizers\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EnZ_hQi5qb14",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WRU7DHoOrYp0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.chdir(\"/content/drive/My Drive/Colab Notebooks/Deep Learning\")\n",
        "\n",
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5ANTVui8i45",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "########################################### PRE PROCESSAMENTO SEM DATA AUGMENTATION ##############################################\n",
        "batch = 32\n",
        "epochs = 10\n",
        "\n",
        "img_x, img_y = 28, 28\n",
        "input_format = (28, 28, 1)\n",
        "num_classes = 10\n",
        "\n",
        "(x_train, y_train), (x_val, y_val)  = mnist.load_data()\n",
        "\n",
        "x_val, x_test, y_val, y_test = train_test_split(x_val, y_val, test_size = 0.5, random_state = 1)\n",
        "\n",
        "x_train = x_train.reshape(x_train.shape[0], img_x, img_y, 1) \n",
        "x_val   = x_val.reshape(x_val.shape[0], img_x, img_y, 1)\n",
        "x_test  = x_test.reshape(x_test.shape[0], img_x, img_y, 1)\n",
        "\n",
        "x_train = x_train.astype('float32') / 255\n",
        "x_val   = x_val.astype('float32') / 255\n",
        "x_test  = x_test.astype('float32') / 255\n",
        "\n",
        "y_train = to_categorical(y_train, num_classes)\n",
        "y_val   = to_categorical(y_val, num_classes)\n",
        "y_test  = to_categorical(y_test, num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PNEq3Ahecb4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##################################################### MODELO SEM DATA AUGMENTATION ###############################################\n",
        "model = Sequential()\n",
        "\n",
        "# C1 --> Primeira camada convolucional, com 6 filtros 5x5 com zeropadding\n",
        "# Imput = 28x28  Output = 28x28\n",
        "model.add(Conv2D(filters = 6, kernel_size=(5, 5), activation='relu', input_shape=input_format, padding='same'))\n",
        "\n",
        "# M1 --> Primeira camada MaxPooling, com stride 2 sem zeropadding\n",
        "# Imput = 28x28  Output = 14x14\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# C2 --> Segunda camada convolucional, com 16 filtros 5x5 sem zeropadding\n",
        "# Imput = 14x14  Output = 10x10\n",
        "model.add(Conv2D(filters = 16, kernel_size=(5, 5), activation='relu'))\n",
        "\n",
        "# M2 --> Segunda camada MaxPooling, com stride 2 sem zeropadding\n",
        "# Imput = 10x10  Output = 5x5\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# C4 --> Quarta camada convolucional, com 120 filtros 5x5 sem zeropadding\n",
        "# Imput = 5x5  Output = 1x1\n",
        "model.add(Conv2D(filters = 120, kernel_size=(5, 5), activation='relu'))\n",
        "\n",
        "#\n",
        "model.add(Flatten())\n",
        "\n",
        "# F1 --> Primeira camada Full Conected, com 84 filtros\n",
        "model.add(Dense(84, activation='relu'))\n",
        "\n",
        "# Camada de Saída\n",
        "model.add(Dense(num_classes, activation = 'softmax', kernel_initializer='glorot_normal'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "checkpoint = ModelCheckpoint('relu-model-{epoch:03d}-{val_acc:03f}-{val_loss:03f}.h5', \n",
        "                             verbose = 1, \n",
        "                             monitor = 'val_acc', \n",
        "                             save_best_only = True,\n",
        "                             mode = 'max')\n",
        "\n",
        "adam = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
        "\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer = adam, metrics=['accuracy'])\n",
        "\n",
        "historico = model.fit(x_train, y_train, batch_size = batch, validation_data=(x_val, y_val), verbose = 1, epochs = epochs, callbacks=[checkpoint])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Pl7dS-XW_Sr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "########################################### PRE PROCESSAMENTO COM DATA AUGMENTATION ##############################################\n",
        "batch = 32\n",
        "epochs = 10\n",
        "\n",
        "img_x, img_y = 28, 28\n",
        "input_format = (img_x, img_y, 1)\n",
        "num_classes = 10\n",
        "\n",
        "(x_train, y_train), (x_val, y_val)  = mnist.load_data()\n",
        "\n",
        "x_val, x_test, y_val, y_test = train_test_split(x_val, y_val, test_size = 0.5, random_state = 1)\n",
        "\n",
        "x_train = x_train.reshape(x_train.shape[0], img_x, img_y, 1) \n",
        "x_val   = x_val.reshape(x_val.shape[0], img_x, img_y, 1)\n",
        "x_test  = x_test.reshape(x_test.shape[0], img_x, img_y, 1)\n",
        "\n",
        "y_train = to_categorical(y_train, num_classes)\n",
        "y_val   = to_categorical(y_val, num_classes)\n",
        "y_test  = to_categorical(y_test, num_classes)\n",
        "\n",
        "x_test  = x_test.astype('float32') / 255\n",
        "\n",
        "train_steps = len(x_train) / batch\n",
        "val_steps = len(x_val) / batch\n",
        "\n",
        "# DATA AUGMENTATION COMEÇA AQUI #\n",
        "train_datagen = ImageDataGenerator(rescale = 1/255,\n",
        "                                   rotation_range = 15,\n",
        "                                   shear_range=0.2,\n",
        "                                   zoom_range=0.2,\n",
        "                                   fill_mode='nearest')\n",
        "                          \n",
        "train_datagen.fit(x_train)\n",
        "\n",
        "val_datagen = ImageDataGenerator(rescale = 1/255,\n",
        "                                 rotation_range = 15,\n",
        "                                 shear_range=0.2,\n",
        "                                 zoom_range=0.2,\n",
        "                                 fill_mode='nearest')\n",
        "val_datagen.fit(x_val)\n",
        "\n",
        "train_generator = train_datagen.flow(x_train, y_train, batch_size = batch, shuffle = True)\n",
        "val_generator = val_datagen.flow(x_val, y_val, batch_size = batch, shuffle = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bu0q74l4GlnV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##################################################### MODELO COM DATA AUGMENTATION ###############################################\n",
        "model = Sequential()\n",
        "\n",
        "# C1 --> Primeira camada convolucional, com 6 filtros 5x5 sem zeropadding\n",
        "# Imput = 28x28  Output = 28x28\n",
        "model.add(Conv2D(filters = 6, kernel_size=(5, 5), activation='relu', input_shape=input_format, padding='same'))\n",
        "\n",
        "# M1 --> Primeira camada MaxPooling, com stride 2 sem zeropadding\n",
        "# Imput = 28x28  Output = 14x14\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# C2 --> Segunda camada convolucional, com 16 filtros 5x5 sem zeropadding\n",
        "# Imput = 14x14  Output = 10x10\n",
        "model.add(Conv2D(filters = 16, kernel_size=(5, 5), activation='relu'))\n",
        "\n",
        "# M2 --> Segunda camada MaxPooling, com stride 2 sem zeropadding\n",
        "# Imput = 10x10  Output = 5x5\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# C4 --> Quarta camada convolucional, com 120 filtros 5x5 sem zeropadding\n",
        "# Imput = 5x5  Output = 1x1\n",
        "model.add(Conv2D(filters = 120, kernel_size=(5, 5), activation='relu'))\n",
        "\n",
        "#\n",
        "model.add(Flatten())\n",
        "\n",
        "# F1 --> Primeira camada Full Conected, com 84 filtros\n",
        "model.add(Dense(84, activation='tanh'))\n",
        "\n",
        "# Camada de Saída\n",
        "model.add(Dense(num_classes, activation = 'softmax', kernel_initializer='glorot_normal'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "checkpoint = ModelCheckpoint('relu-model-{epoch:03d}-{val_acc:03f}-{val_loss:03f}.h5', \n",
        "                             verbose = 1, \n",
        "                             monitor = 'val_acc', \n",
        "                             save_best_only = True,\n",
        "                             mode = 'max')\n",
        "\n",
        "adam = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
        "\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer = adam, metrics=['accuracy'])\n",
        "\n",
        "historico = model.fit_generator(generator = train_generator, \n",
        "                                steps_per_epoch = train_steps,\n",
        "                                validation_data = val_generator,\n",
        "                                validation_steps = val_steps,\n",
        "                                epochs = epochs, \n",
        "                                verbose = 1, \n",
        "                                callbacks = [checkpoint])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZhKIp5atIXPE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Fazendo os Teste\n",
        "score = model.evaluate(x_test, y_test, verbose = 1)\n",
        "print(\"Teste:\\nAcurácia: {}\\tLoss: {}\".format(score[1], score[0]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Xz8clpOvPMC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Gráfico da Acurácia\n",
        "plt.plot(historico.history['acc'], 'o--', color = '#FF1493', label = 'acc-train')    # Deep Pink\n",
        "plt.plot(historico.history['val_acc'], 'o--', color = '#4169E1', label = 'acc-val')  # Royal Blue\n",
        "plt.plot(score[1], 'o', color = '#006400', label = 'acc-test')                       # Dark Green\n",
        "plt.title(\"Comparando os Valores de Acurácia\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Acurácia\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQ2Sbjo48Dcd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Gráfico da Perda\n",
        "plt.plot(historico.history['loss'], 'o--', color = '#DC143C', label = 'loss-train')    # Red - Crimson\n",
        "plt.plot(historico.history['val_loss'], 'o--', color = '#FFD700', label = 'loss-val')  # Gold\n",
        "plt.plot(score[0], 'o', color = '#A0522D', label = 'loss-test')                        # Brown\n",
        "plt.title(\"Comparado os valores de Perda\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y5EgwCVteh2H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from keras.models import load_model\n",
        "\n",
        "# model = load_model('')\n",
        "# model.summary()\n",
        "\n",
        "# score = model.evaluate(x_test, y_test, verbose = 1)\n",
        "# print(\"Teste:\\nAcurácia: {}\\tLoss: {}\".format(score[1], score[0]))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}